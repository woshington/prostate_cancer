{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T02:06:38.833803Z",
     "start_time": "2025-07-31T02:06:37.272489Z"
    }
   },
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import pandas as pd\n",
    "from work.utils.dataset import PandasDataset, MultiColorSpaceTransform\n",
    "from work.utils.models import EfficientNetMultiColor as EfficientNet\n",
    "import albumentations\n",
    "from tqdm import tqdm"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T02:06:39.023050Z",
     "start_time": "2025-07-31T02:06:39.000765Z"
    }
   },
   "source": [
    "output_dimensions = 5\n",
    "data_dir = '../../../dataset'\n",
    "images_dir = os.path.join(data_dir, 'tiles')\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "df_test = pd.read_csv(f\"../../data/test.csv\")\n",
    "backbone_model = 'efficientnet-b0'\n",
    "pretrained_model = {\n",
    "    backbone_model: '/home/woshington/Projects/Doutorado/work/efficientnet-b0-08094119.pth'\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T02:06:39.052392Z",
     "start_time": "2025-07-31T02:06:39.049951Z"
    }
   },
   "source": [
    "print(\"Cuda\", device)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda cuda\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T02:06:39.100211Z",
     "start_time": "2025-07-31T02:06:39.097517Z"
    }
   },
   "cell_type": "code",
   "source": [
    "val_transform =albumentations.Compose([\n",
    "    MultiColorSpaceTransform()\n",
    "])"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T02:06:39.149475Z",
     "start_time": "2025-07-31T02:06:39.147363Z"
    }
   },
   "source": [
    "dataloader = DataLoader(\n",
    "    PandasDataset(images_dir, df_test, transforms=val_transform),\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T02:06:39.464779Z",
     "start_time": "2025-07-31T02:06:39.195663Z"
    }
   },
   "source": [
    "model = EfficientNet(\n",
    "    backbone=backbone_model,\n",
    "    output_dimensions=output_dimensions,\n",
    "    pre_trained_model=pretrained_model\n",
    ")\n",
    "model.load_state_dict(\n",
    "    torch.load(\n",
    "        \"../models/with-noise-mult-color.pth\",\n",
    "        weights_only=True\n",
    "    )\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T02:06:39.477267Z",
     "start_time": "2025-07-31T02:06:39.472603Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def compute_global_channel_importance(model, dataloader, target_class, device=\"cuda\"):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    # Initialize storage for channel gradients across the dataset\n",
    "    all_channel_gradients = []\n",
    "\n",
    "    for images, labels, _ in tqdm(dataloader):  # Assuming dataloader yields (image, label)\n",
    "        images = images.to(device)\n",
    "        images.requires_grad = True\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        target_scores = outputs[:, target_class]\n",
    "\n",
    "        # Backward pass (compute gradients per image in batch)\n",
    "        gradients = []\n",
    "        for score in target_scores:\n",
    "            model.zero_grad()\n",
    "            if images.grad is not None:\n",
    "                images.grad.zero_()\n",
    "            score.backward(retain_graph=True)\n",
    "            gradients.append(images.grad.data.mean(dim=(2, 3)))  # [batch, C]\n",
    "\n",
    "        # Stack gradients for the batch\n",
    "        batch_gradients = torch.stack(gradients).mean(dim=0)  # [batch, C] -> [C]\n",
    "        all_channel_gradients.append(batch_gradients)\n",
    "\n",
    "    # Aggregate across all batches\n",
    "    global_gradients = torch.stack(all_channel_gradients).mean(dim=0)  # [C]\n",
    "\n",
    "    # Get top 3 channels globally\n",
    "    top3_values, top3_indices = torch.topk(global_gradients.abs(), k=3)\n",
    "\n",
    "    return {\n",
    "        \"global_gradients\": global_gradients.cpu().numpy(),\n",
    "        \"top3_indices\": top3_indices.cpu().numpy(),\n",
    "        \"top3_values\": top3_values.cpu().numpy()\n",
    "    }"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T02:45:16.610585Z",
     "start_time": "2025-07-31T02:06:39.527218Z"
    }
   },
   "cell_type": "code",
   "source": [
    "result = compute_global_channel_importance(model, dataloader, target_class=1)\n",
    "\n",
    "print(\"Global Top 3 Channels (Indices):\", result[\"top3_indices\"])\n",
    "print(\"Global Top 3 Channel Gradients:\", result[\"top3_values\"])"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1592/1592 [38:36<00:00,  1.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Top 3 Channels (Indices): [[14  6  4]]\n",
      "Global Top 3 Channel Gradients: [[3.0710787e-08 2.4052094e-08 2.0998312e-08]]\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T02:46:22.597676Z",
     "start_time": "2025-07-31T02:46:22.594414Z"
    }
   },
   "cell_type": "code",
   "source": "print(result[\"global_gradients\"])",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3.04177417e-09 -1.20104602e-08 -1.05012452e-08 -8.68790195e-09\n",
      "   2.09983124e-08  1.42345735e-08  2.40520937e-08 -1.38739304e-08\n",
      "  -1.26334001e-08 -1.08983880e-08  6.57189325e-09 -1.82706614e-08\n",
      "  -1.76451598e-09  4.47961401e-09  3.07107868e-08  8.45942605e-09\n",
      "  -4.39729986e-09 -3.14057980e-09]]\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T03:41:38.693905Z",
     "start_time": "2025-07-31T03:41:38.167219Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "channel_labels = [\n",
    "    'RGB_R', 'RGB_G', 'RGB_B',      # img (RGB)\n",
    "    'XYZ_X', 'XYZ_Y', 'XYZ_Z',      # image_xyz\n",
    "    'HED_H', 'HED_E', 'HED_D',      # image_hed\n",
    "    'LAB_L', 'LAB_A', 'LAB_B',      # image_lab\n",
    "    'CIELUV_L', 'CIELUV_U', 'CIELUV_V', # image_luv\n",
    "    'HSV_H', 'HSV_S', 'HSV_V'       # image_hsv\n",
    "]\n",
    "\n",
    "# Converter lista de arrays para um array 1D de médias por canal\n",
    "arr_2d = np.vstack(result[\"global_gradients\"])  # Se cada item for array 1D\n",
    "grads = arr_2d.mean(axis=0)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "bars = plt.bar(channel_labels, np.abs(grads), color='skyblue')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.ylabel('Channel Importance (|Mean Gradient|)')\n",
    "plt.title('Color Channel Contribution to Target Class Activation')\n",
    "plt.tight_layout()\n",
    "plt.savefig('channel_importance.png')\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 14\u001B[0m\n\u001B[1;32m      4\u001B[0m channel_labels \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m      5\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mRGB_R\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mRGB_G\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mRGB_B\u001B[39m\u001B[38;5;124m'\u001B[39m,      \u001B[38;5;66;03m# img (RGB)\u001B[39;00m\n\u001B[1;32m      6\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mXYZ_X\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mXYZ_Y\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mXYZ_Z\u001B[39m\u001B[38;5;124m'\u001B[39m,      \u001B[38;5;66;03m# image_xyz\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     10\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mHSV_H\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mHSV_S\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mHSV_V\u001B[39m\u001B[38;5;124m'\u001B[39m       \u001B[38;5;66;03m# image_hsv\u001B[39;00m\n\u001B[1;32m     11\u001B[0m ]\n\u001B[1;32m     13\u001B[0m \u001B[38;5;66;03m# Converter lista de arrays para um array 1D de médias por canal\u001B[39;00m\n\u001B[0;32m---> 14\u001B[0m arr_2d \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mvstack(\u001B[43mresult\u001B[49m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mglobal_gradients\u001B[39m\u001B[38;5;124m\"\u001B[39m])  \u001B[38;5;66;03m# Se cada item for array 1D\u001B[39;00m\n\u001B[1;32m     15\u001B[0m grads \u001B[38;5;241m=\u001B[39m arr_2d\u001B[38;5;241m.\u001B[39mmean(axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m     17\u001B[0m plt\u001B[38;5;241m.\u001B[39mfigure(figsize\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m12\u001B[39m, \u001B[38;5;241m6\u001B[39m))\n",
      "\u001B[0;31mNameError\u001B[0m: name 'result' is not defined"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
